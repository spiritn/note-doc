# mysql中的锁

按照锁的模式可以分为：共享锁（S锁），排他锁（X锁）

按照锁的粒度分为：全局锁，表锁，行锁（记录锁，间隙锁，临键锁）


### 共享锁和排它锁

可以作用于表、行等不同粒度，是一种锁的模式。

行锁可以是S锁（SELECT ... LOCK IN SHARE MODE），或X锁（SELECT ... FOR UPDATE）。

意向锁是**表级锁**，是为了修改表时快速判断表中是否有行被加了S/X锁，避免逐行检查，提升性能。

- 事务 A BEGIN; SELECT * FROM t WHERE id = 1 FOR UPDATE;  -- InnoDB 自动： -- 1. 在表 t 上加 IX 锁 -- 2. 在 id=1 的行上加 X 锁 
- 事务 B LOCK TABLES t READ;  -- 尝试在表 t 上加 S 锁 -- 发现表上有 IX 锁 → 冲突！等待事务 A 释放

如果只有行锁，没有意向锁，事务 B 就得扫描全表确认是否有行被 X 锁住 —— 效率极低。

意向锁的作用：**“预告”机制**，当事务要对某行加 X 锁前，**必须先在表上加 IX 锁**。这样，另一个事务如果想对整张表加 S 锁（如 `LOCK TABLES ... READ`），只需检查表上是否有 IX 或 X 锁即可，**无需遍历所有行**。意向锁本身**不阻塞数据操作**，只用于“声明意图”。


## 全局锁

即对整个数据库实例加锁，命令是Flush tables with read lock（FTWRL），效果是整个库处于只读状态，其他线程的DML，DDL和update语句都会被阻塞。全局锁的典型场景就是做全库逻辑备份，即把整库每个表都select出来存成文本。

> 整库备份方法还可以用mysql自带的mysql dump，使用参数--single--transaction的时候，导数据前会启动一个事务，来确保拿到一致性的视图，这个过程中是可以正常更新的！所以库中都是innoDB引擎的话，肯定用mysqlDump来备份是最合适的。

## 表锁

MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

表锁的语法是 lock tables … read/write。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

举个例子, 如果在某个线程A中执行`lock tables t1 read, t2 write;` 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。

在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。

### MDL（metadata lock)锁

另一类表级的锁是MDL（metadata lock)。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

元数据锁：对一个表做增删改查时加MDL读锁；当要对表做结构变更时加MDL写锁。元数据锁MDL，是自动加的，不需要显式使用。表锁：需要手动加。

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 因此线上，对大表进行结构变更时，一定要小心！可能造成慢SQL，数据局不可用等！
  即使小表如果正好有大事务，表锁加锁后，也会影响后续的SQL。

虽然MDL锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。



你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表t是一个小表。

![MDL锁](images/MDL锁.jpg)

我们可以看到session A先启动，这时候会对表t加一个MDL读锁。由于session B需要的也是MDL读锁，因此可以正常执行。

之后session C会被blocked，是因为session A的MDL读锁还没有释放，而session C需要MDL写锁，因此只能被阻塞。

如果只有session C自己被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也会被session C阻塞。前面我们说了，所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表现在完全不可读写了。

如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session再请求的话，这个库的线程很快就会爆满。

你现在应该知道了，事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段？

首先我们要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。

但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？

这时候kill可能未必管用，因为新的请求马上就来了。比较理想的机制是，在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。



## 行锁

行锁：InnoDB引擎特有的一种锁，锁定表的某一行或几行记录，粒度小，并发度高。

- 记录锁：锁定的是某一条记录，属于行锁的一种。
- 间隙锁：属于行锁的一种，锁住一个区间，遵循左开右闭原则。间隙锁只在可重复读的事务隔离级别存在

临键锁：Next-Key Lock，是Innodb的行锁默认算法。简单说就是间隙锁和记录锁的组合，临键锁会把查询出来的记录锁住，同时也会把该查询范围内的所有间隙区间也锁住，把相邻的下一个区间也锁住。

行锁是**加在索引上的**，如果字段没有索引，更新时可能锁表！！！

![锁是作用在索引上的](images/锁是作用在索引上的.jpeg)

行锁是在执行需要的SQL加上，在commit之后才释放，这就代表即使执行完了SQL，但是commit之前插入了其他操作，锁是不会及时释放的，直到事务提交，这就是两阶段锁协议。知道这点，我们在事务中，就应该把最可能造成锁冲突，最可能影响并发度的锁尽量往后放。



#### 快照读和当前读

- 普通 SELECT（快照读）： 在 InnoDB 的默认隔离级别（可重复读 RR）下，**普通的 SELECT 语句是不加锁的！它通过 MVCC（多版本并发控制）**机制读取数据的历史快照，从而实现非阻塞读。
- 加锁读（当前读）： 只有当你显式使用 SELECT ... LOCK IN SHARE MODE（加 S 锁）或者 SELECT ... FOR UPDATE（加 X 锁），以及执行 UPDATE/DELETE 时，才会真正对数据行加上上面提到的共享锁或排他锁。

所以，普通读不需要获取共享锁，是因为它**避开了竞争**。

- **写操作**（X 锁）和 **显式加锁读**（S 锁）是在争夺“原件”的使用权。
- **普通读**则是利用 MVCC 机制，直接拿走了一份“历史复印件”自己看，既不干扰别人修改原件，也不需要去申请对原件的保护（锁）。

这就是 InnoDB 能够支持高并发读的核心秘密：**读不阻塞写，写不阻塞读**。

当前读在实际工作中好像用的并不多，可用在一些减库存，不存在才插入的场景， 一查二判三更新，查是select.. for update。但当前读可能带来锁竞争、死锁概率增加以及吞吐量下降等问题，且受框架封装影响，分库分表等，使用场景更少了。一般用分布式锁即可搞定。

**当前读模式的"少见"源于互联网系统对高并发性能的极致追求，以及分布式架构下更优的并发控制方案的普及**。现代互联网系统普遍采用缓存层(如Redis)、消息队列(如Kafka)、分布式锁等中间层，将并发控制压力转移至这些更高效的组件上



### 死锁和死锁检测

有时MySQL服务器挂了，看CPU使用接近100%，这是怎么回事呢？

数据库出现事务相互等待即进入死锁状态，有两种策略：

1. 直接进入等待，直到超时。但是这个超时时间不好设置，在InnoDB中默认是50s，意味着出现死锁时，第一个被锁的线程要过50秒才会超时退出，其他线程才有可能继续执行，这对于在线业务来说是不可接受的。但是又不能太短比如设置成1秒，虽然可以很快解开死锁，但万一只是锁等待呢？
2. 最常用的策略是**主动死锁检测**。Innodb_deadlock_detect默认就是on。主动死锁检测在发生死锁的时候，能够快速发现并进行处理，但是它也有额外负担。

你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。

那如果是我们上面说到的所有事务都要更新同一行的场景呢？

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个**时间复杂度是O(n)的操作**。**假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级**的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。

根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？问题的症结在于，死锁检测要耗费大量的CPU资源。

一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。

另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有600个客户端，这样即使每个客户端控制到只有5个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到3000。

因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。

可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？

你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成0的时候，代码要有特殊处理。




