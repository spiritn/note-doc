分布式锁主要用来在分布式多实例部署下，保证一个方法在某一时间内只能被一个线程执行。分布式锁的实现方案主要有

## 基于数据库表

最简单的方式是直接创建一张锁表，当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。

创建这样一张数据库表：

```sql
CREATE TABLE `methodLock` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名',
  `desc` varchar(1024) NOT NULL DEFAULT '备注信息',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法';
```

当我们想要锁住某个方法时，执行以下SQL：

```sql
insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)
```

因为我们对`method_name`做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。

当方法执行完毕之后，想要释放锁的话，需要执行以下Sql:

```sql
delete from methodLock where method_name ='method_name'
```

上面这种简单的实现有以下几个问题：

1. 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。

   搞两个数据库，双向同步。一旦挂掉快速切换到备库上。	

2. 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。

   ​	没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。

3. 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。

   搞一个while循环，直到insert成功再返回成功。

4. 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。

   ​	在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。

## 基于数据库排他锁

除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。

我们还用刚刚创建的那张数据库表。可以通过数据库InnoDB引擎的排他锁来实现分布式锁。：

```java
public boolean lock(){
    connection.setAutoCommit(false)
    while(true){
        try{
            result = select * from methodLock where method_name=xxx for update;
            if(result==null){
                return true;
            }
        }catch(Exception e){
        }
        sleep(1000);
    }
    return false;
}
```

在查询语句后面增加`for update`，数据库会在查询过程中给数据库表增加排他锁

> 这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。

我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：

```
public void unlock(){
    connection.commit();
}
```

通过`connection.commit()`操作来释放锁。

这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。

- 阻塞锁？ `for update`语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。
- 锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。

但是还是无法直接解决数据库单点和可重入问题。

这里还可能存在另外一个问题，虽然我们对`method_name` 使用了唯一索引，并且显示使用`for update`来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。。。

还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆



总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。

**数据库实现分布式锁的优点**

直接借助数据库，容易理解。

**数据库实现分布式锁的缺点**

会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。

操作数据库需要一定的开销，性能问题需要考虑。

使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。



## 2. 基于redis的分布式锁

可以自己实现

```java
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.reflect.MethodSignature;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.data.redis.connection.RedisStringCommands;
import org.springframework.data.redis.core.RedisCallback;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.core.types.Expiration;
import org.springframework.stereotype.Component;
import java.lang.reflect.Method;
import java.nio.charset.Charset;
import java.util.Objects;
import java.util.UUID;
import java.util.concurrent.TimeUnit;
@Aspect 
@Component 
public class RedisLockAop {

    private final Logger logger = LoggerFactory.getLogger(RedisLockAop.class);

    private static final Charset UTF8 = Charset.forName("UTF-8");

    private final StringRedisTemplate stringRedisTemplate;

    public RedisLockAop(StringRedisTemplate stringRedisTemplate) {
        this.stringRedisTemplate = stringRedisTemplate;
    }


    @Around("@annotation(*.service.frame.annotation.RedisLock)")
    public Object interceptor(ProceedingJoinPoint pjp) {
        /* 拼接lock key */
        MethodSignature signature = (MethodSignature) pjp.getSignature();
        Method method = signature.getMethod();
        final String lockKey = "redisLock:" + pjp.getSignature().getDeclaringTypeName() + ":" + method.getName();
        String requestId = UUID.randomUUID().toString();
        RedisLock redisLock = method.getAnnotation(RedisLock.class);

        if (!lock(redisLock, lockKey, requestId)) {
            throw new IoTException(ApiCode.REQUEST_FREQUENCY);
        }

        try {
            return pjp.proceed();
        } catch (Throwable throwable) {
            logger.error("aop method execute failed", throwable);
            throw new IoTException(ApiCode.FAIL);
        } finally {
            unlock(lockKey, requestId);
        }
    }


    /**
     * 加锁
     *
     */
    private boolean lock(RedisLock lock, String lockKey, String requestId) {
        long end = System.currentTimeMillis() + lock.timeout() * 1000;
        while (System.currentTimeMillis() < end) {
            if (tryLock(lockKey, requestId, lock.expire(), lock.timeUnit())) {
                return true;
            } else {
                try {
                    logger.info("waiting for acquiring lock");
                    TimeUnit.MILLISECONDS.sleep(200);
                } catch (InterruptedException e) {
                    logger.error("redis lock occurs interrupted exception.", e);
                }
            }
        }
        return false;
    }

    /**
     * 解锁
     */
    private void unlock(String lockKey, String requestId) {
        releaseLock(lockKey, requestId);
    }

    /**
     * 获取分布式锁，原子操作
     *
     * @param lockKey   加锁key
     * @param requestId 加锁请求唯一ID, 可以使用UUID.randomUUID().toString();
     * @param expire    过期时间
     * @param timeUnit  时间单位
     * @return
     */
    private boolean tryLock(String lockKey, String requestId, long expire, TimeUnit timeUnit) {
        try {
            RedisCallback<Boolean> callback = (connection) -> connection.set(lockKey.getBytes(UTF8), requestId.getBytes(UTF8),                                                                            
                                                                             Expiration.seconds(timeUnit.toSeconds(expire)), RedisStringCommands.SetOption.SET_IF_ABSENT);
            return stringRedisTemplate.execute(callback);
        } catch (Exception e) {
            logger.error("redis lock error.", e);
        }
        return false;
    }

    /**
     * 释放锁
     *
     * @param lockKey   加锁key
     * @param requestId 加锁请求唯一ID
     * @return
     */
    private boolean releaseLock(String lockKey, String requestId) {
        String value = stringRedisTemplate.opsForValue().get(lockKey);
        if (Objects.equals(value, requestId)) {
            stringRedisTemplate.delete(lockKey);
            return true;
        }
        logger.error("release redis lock failed, lockKey: {}, requestId: {}.", lockKey, requestId);
        return false;
    }

}
```

可以满足阻塞式，自动失效，可重入的需求。

> 设置timeout是为了阻塞式的获取锁；
>
> 设置expire是为了防止机器down掉没有主动去释放删除锁，所以需要锁自动失效；但是也不能设置的过于大，否则某台机器获取锁后down掉，其他机器要过5分钟才能再次获取锁，大大影响业务！
>
> 设置requestId是为了在高并发场景下，某线程某次执行了很久，锁超过了expire自动失效，然后第二个线程获取锁，但是还没执行完，正好第一个线程执行完把锁释放掉！这样高并发下连锁的导致锁被前一个线程释放掉，造成锁失效。

另外如果任务超时有可能获取锁后突然要执行很久，超过预估的timeout。需要另外线程续命。现有框架redission，后台使用lua脚本，并且1/3时间为这把锁延长时间。

### redLock算法解决单点故障

**在Redis的master节点上拿到了锁，但是这个加锁的key还没有同步到slave节点。master故障，发生故障转移，slave节点升级为master节点，导致锁丢失。怎么办？面试重点**

[redLock官方说明](https://redis.io/topics/distlock)

> 在算法的分布式版本中，我们假设我们有 N 个 Redis 主节点。这些节点是完全独立的，因此我们不使用复制或任何其他隐式协调系统。我们已经描述了如何在单个实例中安全地获取和释放锁。我们理所当然地认为算法会在单个实例中使用这种方法来获取和释放锁。在我们的示例中，我们设置了 N=5，这是一个合理的值，因此我们需要在不同的计算机或虚拟机上运行 5 个 Redis 主节点，以确保它们以几乎独立的方式失败。
>
> 为了获取锁，客户端执行以下操作：
>
> 1. 它以毫秒为单位获取当前时间。
> 2. 它尝试顺序获取所有 N 个实例中的锁，在所有实例中使用相同的键名和随机值。在第 2 步中，在每个实例中设置锁时，客户端使用一个超时时间，该超时时间与总锁自动释放时间相比较小，以便获取它。例如，如果自动释放时间为 10 秒，则超时可能在5-50 毫秒范围内。这可以防止客户端长时间处于阻塞状态，试图与关闭的 Redis 节点对话：如果实例不可用，我们应该尽快尝试与下一个实例对话。
> 3. 客户端通过从当前时间中减去步骤 1 中获得的时间戳来计算获取锁所用的时间。 当且仅当客户端能够在大多数实例（至少 3 个）中获取锁，并且获取锁所用的总时间小于锁有效时间，则认为该锁已获取。
> 4. 如果获得了锁，则其有效时间被视为初始有效时间减去经过的时间，如步骤 3 中计算的那样。
> 5. 如果客户端由于某种原因获取锁失败（或者它无法锁定 N/2+1 个实例或有效时间为负），它将尝试解锁所有实例（即使是它认为没有锁定的实例）能够锁定）。

[redlock分析](https://zhuanlan.zhihu.com/p/151735807)

redisson也支持redlock的算法，使用方式如下：

```java
Config config1 = new Config();
config1.useSingleServer().setAddress("redis://100.100.0.1:5378")
        .setPassword("root").setDatabase(0);
RedissonClient redissonClient1 = Redisson.create(config1);

Config config2 = new Config();
config2.useSingleServer().setAddress("redis://100.100.0.1:5379")
        .setPassword("root").setDatabase(0);
RedissonClient redissonClient2 = Redisson.create(config2);

Config config3 = new Config();
config3.useSingleServer().setAddress("redis://100.100.0.1:5380")
        .setPassword("root").setDatabase(0);
RedissonClient redissonClient3 = Redisson.create(config3);

String resourceName = "REDLOCK";

RLock lock1 = redissonClient1.getLock(resourceName);
RLock lock2 = redissonClient2.getLock(resourceName);
RLock lock3 = redissonClient3.getLock(resourceName);
RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3);
boolean isLock;
try {
    // isLock = redLock.tryLock();
    // 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。
    isLock = redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS);
    System.out.println("isLock = "+isLock);
    if (isLock) {
        //TODO 这里写业务逻辑
    }
} catch (Exception e) {
} finally {
    // 无论如何, 最后都要解锁
    redLock.unlock();
}
```



redission源码简单理解就是循环的取各个主节点获取锁，判断如果成功获取超过n/2+1，就认为加锁成功，否则循环向各个主节点释放锁。

```java
public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException {
    long newLeaseTime = -1;
    if (leaseTime != -1) {
        // 如果等待时间设置了，那么将等待时间 * 2
        newLeaseTime = unit.toMillis(waitTime)*2;
    }

    // time为当前时间戳
    long time = System.currentTimeMillis();
    long remainTime = -1;
    if (waitTime != -1) {
        remainTime = unit.toMillis(waitTime);
    }
    // 计算锁的等待时间，RedLock中：如果remainTime=-1，那么lockWaitTime为1
    long lockWaitTime = calcLockWaitTime(remainTime);

    // RedLock中failedLocksLimit即为n/2 + 1
    int failedLocksLimit = failedLocksLimit();
    List<RLock> acquiredLocks = new ArrayList<RLock>(locks.size());
    // 循环每个redis客户端，去获取锁
    for (ListIterator<RLock> iterator = locks.listIterator(); iterator.hasNext();) {
        RLock lock = iterator.next();
        boolean lockAcquired;
        try {
            // 调用tryLock方法去获取锁，如果获取锁成功，则lockAcquired=true
            if (waitTime == -1 && leaseTime == -1) {
                lockAcquired = lock.tryLock();
            } else {
                //这里也会有锁续约的问题。
                long awaitTime = Math.min(lockWaitTime, remainTime);
                lockAcquired = lock.tryLock(awaitTime, newLeaseTime, TimeUnit.MILLISECONDS);
            }
        } catch (Exception e) {
            lockAcquired = false;
        }

        // 如果获取锁成功，将锁加入到list集合中
        if (lockAcquired) {
            acquiredLocks.add(lock);
        } else {
            // 如果获取锁失败，判断失败次数是否等于失败的限制次数
            // 比如，3个redis客户端，最多只能失败1次
            // 这里locks.size = 3, 3-x=1，说明只要成功了2次就可以直接break掉循环
            if (locks.size() - acquiredLocks.size() == failedLocksLimit()) {
                break;
            }

            // 如果最大失败次数等于0
            if (failedLocksLimit == 0) {
                // 释放所有的锁，RedLock加锁失败
                unlockInner(acquiredLocks);
                if (waitTime == -1 && leaseTime == -1) {
                    return false;
                }
                failedLocksLimit = failedLocksLimit();
                acquiredLocks.clear();
                // 重置迭代器 重试再次获取锁
                while (iterator.hasPrevious()) {
                    iterator.previous();
                }
            } else {
                // 失败的限制次数减一
                // 比如3个redis实例，最大的限制次数是1，如果遍历第一个redis实例，失败了，那么failedLocksLimit会减成0
                // 如果failedLocksLimit就会走上面的if逻辑，释放所有的锁，然后返回false
                failedLocksLimit--;
            }
        }

        if (remainTime != -1) {
            remainTime -= (System.currentTimeMillis() - time);
            time = System.currentTimeMillis();
            if (remainTime <= 0) {
                unlockInner(acquiredLocks);
                return false;
            }
        }
    }

    if (leaseTime != -1) {
        List<RFuture<Boolean>> futures = new ArrayList<RFuture<Boolean>>(acquiredLocks.size());
        for (RLock rLock : acquiredLocks) {
            RFuture<Boolean> future = rLock.expireAsync(unit.toMillis(leaseTime), TimeUnit.MILLISECONDS);
            futures.add(future);
        }

        for (RFuture<Boolean> rFuture : futures) {
            rFuture.syncUninterruptibly();
        }
    }

    return true;
}
```



## 3. 基于zookeeper

非常好，并且也有现成的框架Curator实现，基本唯一的缺点就是性能不高

基于zookeeper临时有序节点可以实现的分布式锁。

大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。



来看下Zookeeper能不能解决前面提到的问题。

- 锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。
- 非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。
- 不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。
- 单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。

可以直接使用zookeeper第三方库[Curator](https://curator.apache.org/)客户端，这个客户端中封装了一个可重入的锁服务。Curator提供的InterProcessMutex是分布式锁的实现。acquire方法用户获取锁，release方法用于释放锁。



Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。

>  其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡)



**使用Zookeeper实现分布式锁的优点**

有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。

**使用Zookeeper实现分布式锁的缺点**

性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。并且需要引入zookeeper。



## 三种方案的比较

上面几种方式，哪种方式都无法做到完美。就像CAP一样，在复杂性、可靠性、性能等方面无法同时满足，所以，根据不同的应用场景选择最适合自己的才是王道。



从实现的难易程度角度（从低到高）

数据库 > 缓存 > Zookeeper



从性能角度（从高到低）

缓存 > Zookeeper >= 数据库



从可靠性角度（从高到低）

Zookeeper > 缓存 > 数据库

# 分布式ID

## Segment

特点

- 高性能、低延迟
- 弱依赖DB,获取下一个号段时才会使用,即使DB或者Server全挂,Client端缓存的Segment也可以使用一段时间
- 单db模式保证下一个id一定比上一个id大,即单调递增;多DB模式ID呈全局递增,但始终唯一,即全局递增

缺点

- 服务重启会丢失号段,造成ID不连续,但保证全局唯一
- ID可预测,存在泄漏发号数量的风险
- 不建议直接外显

场景

- 数据唯一性关联ID,不建议直接用做主键

## Snowflow

特点

- 高性能、低延迟、去中心化、按时间有序
- 生成ID固定64位
- 与指定日期的时间差（毫秒级），41位，够用69年
- 集群ID 机器ID， 10位，最多支持1024台机器
- 序列，12位，每台机器每毫秒内最多产生4096个序列号

缺点

- 强依赖时钟,要求机器时钟同步

场景

- 分布式应用环境的数据主键

# 幂等问题怎么解决？

- select 和delete基本有天然的幂等性
- 通过数据库的唯一索引。如果数据库已经有了，就不再创建。
- 通过token，比如防止页面重复提交。也就是页面要先向服务端申请一个token
- 通过用户ID+设备号+时间戳生成traceId 